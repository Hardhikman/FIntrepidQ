import asyncio
import uuid
import re
from pathlib import Path
from datetime import datetime

import typer
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from rich.prompt import Prompt

from utils import config
from tools.validation import validate_ticker, ValidationError
from utils.cli_logger import setup_logging, analysis_logger, error_logger
from context_engineering import memory
from tools.definitions import resolve_ticker
from agents.chat_agent import build_chat_agent
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from context_engineering.prompts import chat_agent_prompt

# Initialize structured logging
setup_logging(verbose=config.VERBOSE)

app = typer.Typer()
whatsapp_app = typer.Typer()
app.add_typer(whatsapp_app, name="whatsapp", help="WhatsApp integration commands")
console = Console(width=100)

@app.callback()
def callback() -> None:
    """FIntrepidQ Equity Chat CLI"""
    from utils.cli_logger import logger
    logger.print_header()

#HELPER FUNCTIONS (Migrated from main.py)

def _normalize_content(content):
    """
    Normalize content to clean string, handling various formats from LLM responses.
    """
    if content is None:
        return "No content available"
    
    # Handle list of parts (common in Gemini responses)
    if isinstance(content, list):
        parts = []
        for part in content:
            if isinstance(part, dict):
                # Extract text from dict
                if "text" in part:
                    parts.append(str(part["text"]))
                elif "content" in part:
                    parts.append(str(part["content"]))
                else:
                    # Fallback: convert entire dict to string
                    parts.append(str(part))
            elif isinstance(part, str):
                parts.append(part)
            else:
                parts.append(str(part))
        
        text = "\n\n".join(parts)
    elif isinstance(content, dict):
        # Handle dict with text/content key
        if "text" in content:
            text = str(content["text"])
        elif "content" in content:
            text = str(content["content"])
        else:
            text = str(content)
    else:
        # Handle string or other types
        text = str(content)
    
    # Clean up the text
    text = _clean_text(text)
    
    return text


def _clean_text(text: str) -> str:
    """
    Clean and normalize text output.
    """
    # Remove control characters except newlines and tabs
    text = re.sub(r'[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F]', '', text)
    
    # Normalize multiple newlines to max 2
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # Remove trailing whitespace from each line
    lines = [line.rstrip() for line in text.split('\n')]
    text = '\n'.join(lines)
    
    # Remove leading/trailing whitespace from entire text
    text = text.strip()
    
    return text


def _format_report(text: str, ticker: str):
    # Format the report with proper structure and headers.
    return f"# {ticker} - Equity Analysis Report\n\n{text}"

def _extract_whatsapp_summary(text: str):
    """
    Extract Executive Summary and Investment Thesis from the full report for WhatsApp.
    """
    sections = []
    
    # Try to find Executive Summary (flexible matching for emojis/extra text)
    exec_match = re.search(r"## .*?Executive Summary(.*?)(?=\n##|---|$)", text, re.DOTALL | re.IGNORECASE)
    if not exec_match:
        # Fallback to direct match
        exec_match = re.search(r"## Executive Summary(.*?)(?=\n##|---|$)", text, re.DOTALL | re.IGNORECASE)
        
    if exec_match:
        sections.append(f"*Executive Summary*\n{exec_match.group(1).strip()}")
    
    # Try to find Investment Thesis (flexible matching)
    thesis_match = re.search(r"## .*?Investment Thesis(.*?)(?=\n##|---|$)", text, re.DOTALL | re.IGNORECASE)
    if thesis_match:
        sections.append(f"*Investment Thesis*\n{thesis_match.group(1).strip()}")
        
    if not sections:
        # Fallback if parsing fails - return first 1500 chars clean
        return text[:1500].strip() + "\n\n...(Full report available in memory)"
        
    return "\n\n" + "\n\n".join(sections)


def _save_report_to_file(text: str, ticker: str, session_id: str) -> Path:
    """Save report to a markdown file."""
    reports_dir = Path("reports")
    reports_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{ticker}_{timestamp}.md"
    filepath = reports_dir / filename
    
    # Format the report with metadata
    formatted_text = f"""# {ticker} - Equity Analysis Report

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Session ID:** {session_id}

---

{text}

---

*Report generated by FIntrepidQ Equity Analysis System*
"""
    
    filepath.write_text(formatted_text, encoding='utf-8')
    return filepath

def _history_to_messages(history: list[dict]) -> list:
    """Convert internal dict history to LangChain Message objects.
    Always prepend the system prompt.
    """
    msgs: list = [SystemMessage(content=chat_agent_prompt)]
    for entry in history:
        if entry["role"] == "user":
            msgs.append(HumanMessage(content=entry["content"]))
        else:
            msgs.append(AIMessage(content=entry["content"]))
    return msgs

    return str(content)

async def handle_chat_message(user_input: str, history: list, agent, interface: str = "cli", sender_id: str = None, send_func=None):
    """
    Unified handler for chat input from both CLI and WhatsApp.
    Processes commands and AI chat, maintaining consistency.
    """
    from langchain_core.messages import HumanMessage, AIMessage
    user_input = user_input.strip()
    if not user_input:
        return None, True

    content_lower = user_input.lower()
    
    # 1. Handle Commands
    
    # EXIT
    if content_lower in ["/exit", "/quit", "exit", "quit"]:
        if interface == "cli":
            console.print("[yellow]Goodbye![/yellow]")
            return None, False
        return "ðŸ¤– Goodbye!", True

    # CLEAR
    if content_lower == "/clear":
        history.clear()
        history.append(SystemMessage(content=chat_agent_prompt))
        msg = "[yellow]Conversation history cleared.[/yellow]" if interface == "cli" else "ðŸ¤– Conversation history cleared."
        return msg, True

    # TICKERS
    if content_lower == "/tickers":
        # Pass a specific prompt to the agent to list tickers
        user_input = "List all analyzed tickers."
    
    # HELP
    if content_lower == "/help":
        help_text = (
            "*Commands:*\n"
            "- analyze [ticker] : Start full analysis\n"
            "- /compare [ticker]: Compare stock with sector peers\n"
            "- /tickers : List analyzed tickers\n"
            "- /help : Show this message\n"
            "- /clear : Clear history\n"
            "- /exit : Exit chat"
        )
        if interface == "cli":
            console.print(Panel(help_text.replace("*", ""), title="Help"))
            return None, True
        return f"ðŸ¤– {help_text}", True

    # ANALYZE
    if content_lower.startswith("analyze "):
        ticker_input = user_input.split(None, 1)[1].strip()
        
        # Resolve ticker for consistent graph execution
        try:
            ticker = resolve_ticker(ticker_input)
            ticker = validate_ticker(ticker)
        except Exception as e:
            msg = f"âŒ Invalid ticker '{ticker_input}': {e}"
            return f"ðŸ¤– {msg}" if interface == "whatsapp" else f"[red]{msg}[/red]", True

        if interface == "whatsapp":
            if send_func:
                send_func(sender_id, f"ðŸ¤– Starting full analysis for {ticker}... This may take 1-2 minutes.")
            
            # Run analysis pipeline (non-interactive)
            try:
                from agents.graph import build_graph
                import uuid as _uuid
                
                app_graph = build_graph()
                graph_config = {"configurable": {"thread_id": str(_uuid.uuid4())}}
                
                # Stream through the graph
                async for ev in app_graph.astream({"ticker": ticker}, graph_config, stream_mode="values"):
                    pass
                
                snapshot = app_graph.get_state(graph_config)
                if snapshot.next:
                    # Auto-resolve conflicts
                    app_graph.update_state(graph_config, {"conflicts": []})
                    async for ev in app_graph.astream(None, graph_config, stream_mode="values"):
                        pass
                    snapshot = app_graph.get_state(graph_config)
                
                current_state = snapshot.values
                if current_state and "final_report" in current_state:
                    report_text = _format_report(current_state["final_report"], ticker)
                    session_id = f"analysis_{ticker}_{_uuid.uuid4().hex[:6]}"
                    await memory.save_analysis_to_memory(
                        session_id=session_id,
                        user_id=config.DEFAULT_USER_ID,
                        ticker=ticker,
                        report=report_text,
                    )
                    return f"ðŸ¤– ðŸ“Š *{ticker} Analysis Report Summary*\n{_extract_whatsapp_summary(report_text)}", True
                else:
                    return f"ðŸ¤– âŒ Analysis for {ticker} failed.", True
            except Exception as e:
                return f"ðŸ¤– âŒ Analysis error: {str(e)[:100]}", True
        else:
            # CLI behavior (interactive)
            await run_analysis_workflow(ticker)
            return None, True

    # COMPARE
    if content_lower.startswith("/compare "):
        parts = user_input.split(maxsplit=1)
        if len(parts) > 1:
            ticker = parts[1].strip().upper()
            user_input = f"Compare {ticker} with its sector peers."
        else:
            msg = "Usage: /compare [ticker]"
            return f"ðŸ¤– {msg}" if interface == "whatsapp" else f"[red]{msg}[/red]", True

    # WHATSAPP LOGIN (CLI only)
    if interface == "cli" and content_lower == "/whatsapp login":
        from tools.whatsapp_client import WhatsAppClient
        WhatsAppClient().login()
        return None, True

    # 2. AI Chat Processing
    history.append(HumanMessage(content=user_input))
    
    try:
        if interface == "cli":
            with console.status("[bold green]Thinking...[/bold green]"):
                result = await agent.ainvoke({"messages": history})
        else:
            result = await agent.ainvoke({"messages": history})
            
        response = _extract_response_content(result["messages"][-1].content)
        history.append(AIMessage(content=response))
        
        if interface == "cli":
            console.print("\n[bold blue]AI:[/bold blue]")
            console.print(Markdown(response))
            return None, True
        else:
            return f"ðŸ¤– {response}", True
            
    except Exception as e:
        msg = f"Error: {e}"
        return f"ðŸ¤– {msg}" if interface == "whatsapp" else f"[red]{msg}[/red]", True

async def run_analysis_workflow(ticker: str, user_id: str = None, save_file: bool = True, auto_save: bool = False):
    """
    Async implementation of the analysis workflow using LangGraph.
    Features clean CLI logging with spinners and progress tracking.
    
    Args:
        ticker: Stock ticker symbol or company name
        user_id: User identifier for database storage
        save_file: Whether to save report to markdown file
        auto_save: If True, skip confirmation prompt and save to both file and database
    """
    from utils.cli_logger import logger
    import time
    
    start_time = time.time()
    user_id = user_id or config.DEFAULT_USER_ID
    
    # Input validation - validate and sanitize ticker
    try:
        original_input = ticker
        ticker = resolve_ticker(ticker)
    
        ticker = validate_ticker(ticker)
        
        if ticker != original_input.upper():
            logger.log_success(f"Resolved '{original_input}' to ticker: {ticker}")
    except ValidationError as e:
        error_logger.log_validation_error("ticker", ticker, str(e))
        logger.log_error(f"Invalid input: {e}")
        console.print(f"[red]âŒ {e}[/red]")
        return

    # Log analysis start
    analysis_logger.info(f"Starting analysis for {ticker}", {
        "event": "analysis_start",
        "ticker": ticker,
        "user_id": user_id,
        "original_input": original_input
    })

    # Initialize analysis tracking
    logger.start_analysis(ticker)

    session_id = f"analysis_{ticker}_{uuid.uuid4().hex[:6]}"

    try:
        from agents.graph import build_graph
        
        app = build_graph()
        
        # Config for the graph execution
        thread_id = str(uuid.uuid4())
        graph_config = {"configurable": {"thread_id": thread_id}}
        
        initial_state = {"ticker": ticker}
        
        # Run the graph until the first interruption or completion
        current_state = None
        
        # Initial run with phase tracking
        async for event in app.astream(initial_state, graph_config, stream_mode="values"):
            if "data_result" in event and "validation_result" not in event:
                logger.tracker.complete_phase("Data Collection")
            elif "validation_result" in event and "analysis_result" not in event:
                logger.tracker.complete_phase("Validation")
                if event.get("conflicts"):
                    logger.log_warning(f"{len(event['conflicts'])} Data Conflicts Detected!")

        # Check if we are interrupted
        snapshot = app.get_state(graph_config)
        
        if snapshot.next:
            # We are interrupted!
            logger.console.print("\n[bold red]ðŸ›‘ Workflow Paused: Human Review Required[/bold red]")
            
            state_values = snapshot.values
            conflicts = state_values.get("conflicts", [])
            data_result = state_values.get("data_result", {})
            financial_data = data_result.get("financial_data", {})
            
            if conflicts:
                logger.print_panel(f"Found {len(conflicts)} discrepancies between Yahoo Finance and Alpha Vantage.", title="Conflict Resolution", style="red")
                
                for conflict in conflicts:
                    metric = conflict['metric']
                    val_primary = conflict['primary_value']
                    val_ref = conflict['reference_value']
                    diff = conflict['diff_percent']
                    
                    logger.console.print(f"\n[bold]Conflict for '{metric}' (Diff: {diff:.2f}%):[/bold]")
                    logger.console.print(f"1. Yahoo Finance: [cyan]{val_primary}[/cyan]")
                    logger.console.print(f"2. Alpha Vantage: [magenta]{val_ref}[/magenta]")
                    
                    choice = typer.prompt("Select source to use (1/2)", type=int)
                    
                    if choice == 2:
                        logger.log_success(f"Updated {metric} to {val_ref}")
                        financial_data[metric] = val_ref
                    else:
                        logger.console.print(f"[dim]Keeping Yahoo Finance value: {val_primary}[/dim]")
                
                # Update state and resume
                data_result['financial_data'] = financial_data
                app.update_state(graph_config, {"data_result": data_result, "conflicts": []})
                
                # Continue execution
                async for event in app.astream(None, graph_config, stream_mode="values"):
                    if "analysis_result" in event and "final_report" not in event:
                        logger.tracker.complete_phase("Analysis")
                    elif "final_report" in event:
                        logger.tracker.complete_phase("Synthesis")
                        current_state = event

        else:
            current_state = snapshot.values
            # Mark remaining phases as complete if they were in state
            if current_state.get("analysis_result"):
                logger.tracker.complete_phase("Analysis")
            if current_state.get("final_report"):
                logger.tracker.complete_phase("Synthesis")

        # Final Output
        if current_state and "final_report" in current_state:
            final_report = current_state["final_report"]
            final_text = _format_report(final_report, ticker)

            # Show progress summary
            logger.print_summary()

            logger.print_panel(
                Markdown(final_text),
                title=f"ðŸ“Š {ticker} Analysis Report", 
                style="cyan"
            )

            # Human-in-the-loop: Ask user for save confirmation
            if not auto_save:
                save_choice = Prompt.ask(
                    "\n[bold yellow]ðŸ’¾ Save this report?[/bold yellow]\n"
                    "  [cyan]yes[/cyan] = Save to file AND database\n"
                    "  [cyan]no[/cyan] = Save to file only\n"
                    "  [cyan]cancel[/cyan] = Discard report",
                    choices=["yes", "no", "cancel"],
                    default="yes"
                )
                
                if save_choice == "cancel":
                    logger.log_warning("Report discarded by user.")
                    return
            else:
                save_choice = "yes"  # Auto-save mode saves to both
            
            # Save to file (always, unless cancelled)
            if save_file:
                filepath = _save_report_to_file(final_text, ticker, session_id)
                logger.log_success(f"Report saved to: {filepath}")
            
            # Save to database only if user chooses "yes"
            if save_choice == "yes":
                await memory.save_analysis_to_memory(
                    session_id=session_id,
                    user_id=user_id,
                    ticker=ticker,
                    report=final_text,
                )
                logger.log_success("Report saved to database.")
            else:
                console.print("[dim]Report saved to file only (not added to database).[/dim]")

        elif current_state and current_state.get("data_result", {}).get("status") == "error":
            # Workflow aborted due to critical data collection failure
            error_msg = current_state.get("data_result", {}).get("error", "Unknown error")
            logger.console.print(f"\n[bold red]âŒ Analysis aborted: {error_msg}[/bold red]")
            logger.console.print("[yellow]ðŸ’¡ Tip: Wait for API quota to reset or check your API key.[/yellow]")
        else:
            logger.console.print(f"\n[red]Analysis incomplete - no report generated.[/red]")

    except Exception as e:
        logger.log_error(f"ERROR: {e}")
        import traceback
        traceback.print_exc()

@app.command()
def analyze(
    ticker: str,
    user_id: str = None,
    save_file: bool = typer.Option(True, "--save-file/--no-save-file", help="Save report to markdown file"),
    stream: bool = typer.Option(True, "--stream/--no-stream", help="Stream agent events in real-time"),
    auto_save: bool = typer.Option(False, "--auto-save", help="Skip confirmation prompt, save to both file and database")
):
    """
    Run multi-agent equity analysis on a stock ticker.
    
    After analysis, you will be prompted to save the report:
    - 'yes': Save to file AND database
    - 'no': Save to file only
    - 'cancel': Discard the report
    
    Use --auto-save to skip the prompt and save to both automatically.
    """
    asyncio.run(run_analysis_workflow(ticker, user_id, save_file, auto_save))


async def run_chat_loop(initial_ticker: str | None = None) -> None:
    """Main chat loop."""
    console.print(
        Panel.fit(
            "[bold cyan]ðŸ¤– FIntrepidQ Equity Chat[/bold cyan]\n\n"
            "Ask questions about your analyzed stocks or use commands:\n"
            "- [bold yellow]analyze [ticker][/bold yellow]  : Run a full deep-dive analysis\n"
            "- [bold yellow]/compare [ticker][/bold yellow] : Benchmark against sector peers\n"
            "- [bold yellow]/tickers[/bold yellow]         : List all analyzed stocks\n"
            "- [bold yellow]/help[/bold yellow]            : Show all available commands\n"
            "- [bold yellow]/exit[/bold yellow]            : Exit the chat interface",
            border_style="cyan",
        )
    )

    agent = build_chat_agent()
    chat_history: list[dict] = []

    # Optional initial ticker context
    if initial_ticker:
        initial_msg = f"Tell me about {initial_ticker} based on the analysis."
        console.print(f"\n[bold green]You:[/bold green] {initial_msg}")
        chat_history.append({"role": "user", "content": initial_msg})
        with console.status("[bold green]Thinking...[/bold green]"):
            msgs = _history_to_messages(chat_history)
            result = await agent.ainvoke({"messages": msgs})
            response = _extract_response_content(result["messages"][-1].content)
        chat_history.append({"role": "assistant", "content": response})
        console.print("\n[bold blue]AI:[/bold blue]")
        console.print(Markdown(response))

    while True:
        try:
            from rich.prompt import Prompt
            user_input = Prompt.ask("\n[bold green]You[/bold green]")
            
            response, should_continue = await handle_chat_message(
                user_input, 
                _history_to_messages(chat_history) if not chat_history else chat_history, 
                agent, 
                interface="cli"
            )
            
            if response:
                console.print(response)
            
            if not should_continue:
                break
                
            # Note: We need to maintain the LangChain message objects in history now
            # since the unified handler appends to it.
            if not chat_history:
                # Initialize history if empty
                chat_history = [SystemMessage(content=chat_agent_prompt)]
                
        except KeyboardInterrupt:
            console.print("\n[yellow]Goodbye![/yellow]")
            break
        except Exception as e:
            console.print(f"\n[red]Error: {e}[/red]")

@whatsapp_app.command("login")
def whatsapp_login():
    """Login to WhatsApp by scanning a QR code."""
    from tools.whatsapp_client import WhatsAppClient
    client = WhatsAppClient()
    client.login()

@whatsapp_app.command("send")
def whatsapp_send(
    message: str = typer.Argument(..., help="Message content"),
    phone: str = typer.Option(None, help="Phone number with country code (e.g., 919876543210). Defaults to env var.")
):
    """Send a WhatsApp message."""
    from tools.whatsapp_client import WhatsAppClient
    
    target_phone = phone or config.WHATSAPP_DEFAULT_TO_NUMBER
    
    if not target_phone:
        console.print("[red]Error: Phone number is required. Provide it as an argument or set WHATSAPP_DEFAULT_TO_NUMBER in .env[/red]")
        raise typer.Exit(code=1)
        
    client = WhatsAppClient()
    if client.send_message(target_phone, message):
        console.print(f"[green]Message sent to {target_phone}![/green]")
    else:
        console.print(f"[red]Failed to send message to {target_phone}.[/red]")

@whatsapp_app.command("run-bot")
def whatsapp_run_bot():
    """
    Run the WhatsApp bot listener.
    Listens for incoming messages and replies using the AI agent.
    """
    from tools.whatsapp_client import WhatsAppClient
    from agents.chat_agent import build_chat_agent
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    from context_engineering.prompts import chat_agent_prompt
    import asyncio

    console.print(Panel.fit("[bold green]WhatsApp Bot Listener Running...[/bold green]\nWaiting for messages...", border_style="green"))
    
    client = WhatsAppClient()
    agent = build_chat_agent()

    # We need a way to manage conversation history per user (phone number)
    # For simplicity in this CLI version, we'll keep a simple in-memory dict
    # format: {phone_number: [message_history]}
    conversations = {}
    
    # Store the sender function from the listener
    whatsapp_send_func = None
    
    def set_send_func(func):
        nonlocal whatsapp_send_func
        whatsapp_send_func = func

    try:
        for event in client.listen_for_messages(provide_input_channel=set_send_func):
            if event.get("type") == "message":
                sender = event.get("sender")
                content = event.get("content")
                
                console.print(f"\n[blue]ðŸ“© Received from {sender}:[/blue] {content}")
                
                if sender not in conversations:
                    conversations[sender] = [SystemMessage(content=chat_agent_prompt)]
                
                history = conversations[sender]
                
                async def process_and_reply():
                    response, _ = await handle_chat_message(
                        content, 
                        history, 
                        agent, 
                        interface="whatsapp", 
                        sender_id=sender,
                        send_func=whatsapp_send_func
                    )
                    if response and whatsapp_send_func:
                        console.print(f"[green]ðŸ“¤ Replying to {sender}:[/green] {response[:50]}...")
                        whatsapp_send_func(sender, response)

                asyncio.run(process_and_reply())
                
            elif event.get("type") == "system":
                content = event.get("content")
                if content == "READY":
                    console.print("[bold green]âœ… WhatsApp Bot CONNECTED and Ready![/bold green]")
                elif content == "HEARTBEAT":
                    # Periodic log to show listener is still alive
                    console.print("[dim]ðŸ’“ Heartbeat received from listener...[/dim]")
                
            elif event.get("type") == "unknown":
                console.print(f"[dim]Unknown event: {event.get('raw')}[/dim]")
                
    except KeyboardInterrupt:
        console.print("\n[yellow]Bot stopped by user.[/yellow]")
    except Exception as e:
        import traceback
        console.print(f"\n[red]Fatal bot error: {e}[/red]")
        console.print(f"[dim]{traceback.format_exc()}[/dim]")
    finally:
        console.print("[bold red]Bot shutdown complete.[/bold red]")

@app.command()
def start(ticker: str = typer.Argument(None)):
    """Start the chat interface."""
    asyncio.run(run_chat_loop(ticker))

if __name__ == "__main__":
    app()