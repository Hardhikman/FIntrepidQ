import asyncio
import uuid
import re
from pathlib import Path
from datetime import datetime

import typer
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from rich.prompt import Prompt

import config
from context_engineering import memory
from tools.definitions import resolve_ticker
from agents.chat_agent import build_chat_agent
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from context_engineering.prompts import chat_agent_prompt

app = typer.Typer()
console = Console(width=100)

@app.callback()
def callback() -> None:
    """Intrepidq Equity Chat CLI"""
    pass

#HELPER FUNCTIONS (Migrated from main.py)

def _normalize_content(content):
    """
    Normalize content to clean string, handling various formats from LLM responses.
    """
    if content is None:
        return "No content available"
    
    # Handle list of parts (common in Gemini responses)
    if isinstance(content, list):
        parts = []
        for part in content:
            if isinstance(part, dict):
                # Extract text from dict
                if "text" in part:
                    parts.append(str(part["text"]))
                elif "content" in part:
                    parts.append(str(part["content"]))
                else:
                    # Fallback: convert entire dict to string
                    parts.append(str(part))
            elif isinstance(part, str):
                parts.append(part)
            else:
                parts.append(str(part))
        
        text = "\n\n".join(parts)
    elif isinstance(content, dict):
        # Handle dict with text/content key
        if "text" in content:
            text = str(content["text"])
        elif "content" in content:
            text = str(content["content"])
        else:
            text = str(content)
    else:
        # Handle string or other types
        text = str(content)
    
    # Clean up the text
    text = _clean_text(text)
    
    return text


def _clean_text(text: str) -> str:
    """
    Clean and normalize text output.
    """
    # Remove control characters except newlines and tabs
    text = re.sub(r'[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F]', '', text)
    
    # Normalize multiple newlines to max 2
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # Remove trailing whitespace from each line
    lines = [line.rstrip() for line in text.split('\n')]
    text = '\n'.join(lines)
    
    # Remove leading/trailing whitespace from entire text
    text = text.strip()
    
    return text


def _format_report(text: str, ticker: str) -> str:
    """Format the report with proper structure and headers."""
    # Add header if not present
    if not text.startswith('#') and ticker.upper() not in text[:100]:
        header = f"# {ticker} - Equity Analysis Report\n\n"
        text = header + text
    
    return text


def _save_report_to_file(text: str, ticker: str, session_id: str) -> Path:
    """Save report to a markdown file."""
    reports_dir = Path("reports")
    reports_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{ticker}_{timestamp}.md"
    filepath = reports_dir / filename
    
    # Format the report with metadata
    formatted_text = f"""# {ticker} - Equity Analysis Report

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Session ID:** {session_id}

---

{text}

---

*Report generated by IntrepidQ Equity Analysis System*
"""
    
    filepath.write_text(formatted_text, encoding='utf-8')
    return filepath

def _history_to_messages(history: list[dict]) -> list:
    """Convert internal dict history to LangChain Message objects.
    Always prepend the system prompt.
    """
    msgs: list = [SystemMessage(content=chat_agent_prompt)]
    for entry in history:
        if entry["role"] == "user":
            msgs.append(HumanMessage(content=entry["content"]))
        else:
            msgs.append(AIMessage(content=entry["content"]))
    return msgs

def _extract_response_content(content: str | list) -> str:
    """Extract text content from potential list structure."""
    if isinstance(content, list):
        text_parts = []
        for item in content:
            if isinstance(item, dict) and "text" in item:
                text_parts.append(item["text"])
        return "".join(text_parts)
    return str(content)

async def run_analysis_workflow(ticker: str, user_id: str = None, save_file: bool = True):
    """
    Async implementation of the analysis workflow using LangGraph.
    """
    user_id = user_id or config.DEFAULT_USER_ID
    
    # Resolve ticker if it's a company name
    original_input = ticker
    ticker = resolve_ticker(ticker)
    
    if ticker != original_input.upper():
        console.print(f"[bold yellow]ðŸ” Resolved '{original_input}' to ticker: {ticker}[/bold yellow]")

    console.print(f"\n[bold blue]ðŸš€ Multi-Agent System: Analyzing {ticker}...[/bold blue]\n")

    session_id = f"analysis_{ticker}_{uuid.uuid4().hex[:6]}"

    try:
        from agents.graph import build_graph
        from langchain_core.messages import Command
        
        app = build_graph()
        
        # Config for the graph execution
        thread_id = str(uuid.uuid4())
        graph_config = {"configurable": {"thread_id": thread_id}}
        
        initial_state = {"ticker": ticker}
        
        console.print("[bold cyan]ðŸ”„ Starting Workflow...[/bold cyan]")
        
        # Run the graph until the first interruption or completion
        current_state = None
        
        # Initial run
        async for event in app.astream(initial_state, graph_config, stream_mode="values"):
            # Simple progress logging based on state keys
            if "data_result" in event and "validation_result" not in event:
                console.print("[green]âœ“ Data Collection Complete[/green]")
            elif "validation_result" in event and "analysis_result" not in event:
                    console.print("[green]âœ“ Validation Complete[/green]")
                    # Check for conflicts in the event (snapshot)
                    if event.get("conflicts"):
                        console.print(f"[yellow]âš ï¸  {len(event['conflicts'])} Data Conflicts Detected![/yellow]")

        # Check if we are interrupted
        snapshot = app.get_state(graph_config)
        
        if snapshot.next:
            # We are interrupted!
            console.print("\n[bold red]ðŸ›‘ Workflow Paused: Human Review Required[/bold red]")
            
            state_values = snapshot.values
            conflicts = state_values.get("conflicts", [])
            data_result = state_values.get("data_result", {})
            financial_data = data_result.get("financial_data", {})
            
            if conflicts:
                console.print(Panel(f"Found {len(conflicts)} discrepancies between Yahoo Finance and Alpha Vantage.", title="Conflict Resolution", border_style="red"))
                
                for conflict in conflicts:
                    metric = conflict['metric']
                    val_primary = conflict['primary_value']
                    val_ref = conflict['reference_value']
                    diff = conflict['diff_percent']
                    
                    console.print(f"\n[bold]Conflict for '{metric}' (Diff: {diff:.2f}%):[/bold]")
                    console.print(f"1. Yahoo Finance: [cyan]{val_primary}[/cyan]")
                    console.print(f"2. Alpha Vantage: [magenta]{val_ref}[/magenta]")
                    
                    choice = typer.prompt("Select source to use (1/2)", type=int)
                    
                    if choice == 2:
                        console.print(f"[green]Updating {metric} to {val_ref}[/green]")
                        financial_data[metric] = val_ref
                    else:
                        console.print(f"[dim]Keeping Yahoo Finance value: {val_primary}[/dim]")
                
                console.print("\n[bold cyan]ðŸ”„ Resuming Workflow...[/bold cyan]")
                
                # Update state and resume
                data_result['financial_data'] = financial_data
                
                app.update_state(graph_config, {"data_result": data_result, "conflicts": []})
                
                # Continue execution
                async for event in app.astream(None, graph_config, stream_mode="values"):
                        if "analysis_result" in event and "final_report" not in event:
                            console.print("[green]âœ“ Analysis Complete[/green]")
                        elif "final_report" in event:
                            console.print("[green]âœ“ Synthesis Complete[/green]")
                            current_state = event

        else:
            current_state = snapshot.values

        # Final Output
        if current_state and "final_report" in current_state:
            final_report = current_state["final_report"]
            final_text = _format_report(final_report, ticker)

            console.print("\n")
            console.print(Panel(
                Markdown(final_text),
                title=f"[bold cyan]ðŸ“Š {ticker} Analysis Report[/bold cyan]",
                border_style="cyan",
                padding=(1, 2)
            ))
            console.print("\n[bold green]âœ… Multi-Agent Analysis Complete![/bold green]\n")

            # Save to database
            await memory.save_analysis_to_memory(
                session_id=session_id,
                user_id=user_id,
                ticker=ticker,
                report=final_text,
            )
            
            # Save to file if requested
            if save_file:
                filepath = _save_report_to_file(final_text, ticker, session_id)
                console.print(f"[dim]ðŸ’¾ Report saved to: {filepath}[/dim]\n")

    except Exception as e:
        console.print(f"\n[bold red]âŒ ERROR:[/bold red] {e}\n")
        import traceback
        traceback.print_exc()

@app.command()
def analyze(
    ticker: str,
    user_id: str = None,
    save_file: bool = typer.Option(True, "--save-file/--no-save-file", help="Save report to markdown file"),
    stream: bool = typer.Option(True, "--stream/--no-stream", help="Stream agent events in real-time")
):
    """
    Run multi-agent equity analysis on a stock ticker.
    """
    asyncio.run(run_analysis_workflow(ticker, user_id, save_file))


async def run_chat_loop(initial_ticker: str | None = None) -> None:
    """Main chat loop."""
    console.print(
        Panel.fit(
            "[bold cyan]ðŸ¤– Intrepidq Equity Chat[/bold cyan]\n\n"
            "Ask questions about your analyzed stocks.\n"
            "Type [bold yellow]analyze [ticker][/bold yellow] to start a new analysis.\n"
            "Type [bold yellow]/help[/bold yellow] for commands, "
            "[bold yellow]/exit[/bold yellow] to quit.",
            border_style="cyan",
        )
    )

    agent = build_chat_agent()
    chat_history: list[dict] = []

    # Optional initial ticker context
    if initial_ticker:
        initial_msg = f"Tell me about {initial_ticker} based on the analysis."
        console.print(f"\n[bold green]You:[/bold green] {initial_msg}")
        chat_history.append({"role": "user", "content": initial_msg})
        with console.status("[bold green]Thinking...[/bold green]"):
            msgs = _history_to_messages(chat_history)
            result = await agent.ainvoke({"messages": msgs})
            response = _extract_response_content(result["messages"][-1].content)
        chat_history.append({"role": "assistant", "content": response})
        console.print("\n[bold blue]AI:[/bold blue]")
        console.print(Markdown(response))

    while True:
        try:
            user_input = Prompt.ask("\n[bold green]You[/bold green]")
            user_input = user_input.strip()
            if not user_input:
                continue
            
            # Commands
            if user_input.lower() in ["/exit", "/quit", "exit", "quit"]:
                console.print("[yellow]Goodbye![/yellow]")
                break
            
            # Intercept 'analyze' command
            if user_input.lower().startswith("analyze "):
                _, t = user_input.split(maxsplit=1)
                await run_analysis_workflow(t)
                continue
                
            if user_input.lower() == "/help":
                console.print(
                    Panel(
                        "[bold]Commands:[/bold]\n"
                        "- analyze [ticker] : Start full analysis\n"
                        "- /tickers : List analyzed tickers\n"
                        "- /clear   : Clear conversation history\n"
                        "- /exit    : Exit chat",
                        title="Help",
                    )
                )
                continue
            if user_input.lower() == "/tickers":
                user_input = "List all analyzed tickers."
            if user_input.lower() == "/clear":
                chat_history = []
                console.print("[yellow]Conversation history cleared.[/yellow]")
                continue
                
            # Add user message
            chat_history.append({"role": "user", "content": user_input})
            with console.status("[bold green]Thinking...[/bold green]"):
                msgs = _history_to_messages(chat_history)
                result = await agent.ainvoke({"messages": msgs})
                response = _extract_response_content(result["messages"][-1].content)
            chat_history.append({"role": "assistant", "content": response})
            console.print("\n[bold blue]AI:[/bold blue]")
            console.print(Markdown(response))
        except KeyboardInterrupt:
            console.print("\n[yellow]Goodbye![/yellow]")
            break
        except Exception as e:
            console.print(f"\n[red]Error: {e}[/red]")

@app.command()
def start(ticker: str = typer.Argument(None)):
    """Start the chat interface."""
    asyncio.run(run_chat_loop(ticker))

if __name__ == "__main__":
    app()